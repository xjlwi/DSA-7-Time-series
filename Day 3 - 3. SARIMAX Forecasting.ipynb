{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('env01': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c664dd3dfd0443172333d91ad28e36a5da0aac789b86e21c590d0fec45d79915"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Styling notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"rise.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<div style=\"font-size:2em; text-align:center; margin-top:30px; margin-bottom:20px\">Data Science Academy 7</div>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "<div style=\"font-size:4em; text-align:center; margin-bottom:30px; color:#00746E\"><b>SARIMAX</b></div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualisation\n",
    "import matplotlib.pyplot as plt # data visualisation\n",
    "import datetime as dt # working with time data\n",
    "import plotly.graph_objs as go # plotly graphical object\n",
    "\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../input/demand_store_forecast/train.csv')\n",
    "buf = df[(df['store'] == 1) & (df['item'] == 1)].copy() # item 1 in store 5\n",
    "buf = buf.set_index('date')\n",
    "buf.index = pd.DatetimeIndex(buf.index).to_period('D')\n",
    "y = buf['sales']\n",
    "# y_to_train = y.iloc[:(len(y)-365)]\n",
    "# y_to_test = y.iloc[(len(y)-365):] # last year for testing"
   ]
  },
  {
   "source": [
    "## <a href='1'>1. Time Series Forecasting</a>\n",
    "\n",
    "## <a href='1.1'>1.1 SARIMAX preparation</a>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The plot below shows the sales of Item 1 in the store. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(1,1,figsize=(15,5))\n",
    "y.plot(ax=ax1)\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Sales of Item 1\")\n",
    "ax1.set_title (\"Store 1\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "source": [
    "## Train test Split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "tr_start,tr_end = '2014-01-01','2017-09-30'\n",
    "te_start,te_end = '2017-10-01','2017-12-31'\n",
    "tra = buf['sales'][tr_start:tr_end].dropna()\n",
    "tes = buf['sales'][te_start:te_end].dropna()"
   ]
  },
  {
   "source": [
    "The Augmented Dickey-Fuller test can be used to test for stationarity of our time series. The null hypothesis of the test is that the <u>time series is not stationary</u> (has some time-dependent structure).\n",
    "\n",
    "<font color= '#bfd730'> Null Hypothesis (H0): if failed to be rejected (high p-value) means it is non-stationary\n",
    "\n",
    "Null Hypothesis (H1): if H0 is rejected (low p-value) means it is stationary</font>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "results = adfuller(buf['sales']['2015-01-01':].dropna(), regression = 'ct')\n",
    "print('ADF Statistic: %f' % results[0])\n",
    "print('p-value: %f' % results[1])"
   ]
  },
  {
   "source": [
    "No surprise. P-value is 0.56 (we don't reject H0) - time series is <u>not stationary</u>. \n",
    "\n",
    "To better understand the time series behaviour I will decompose it into <font color='#20419b'>trend, seasonality and residuals.</font>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "What is adfuller method parameter 'regression'?\n",
    "\n",
    "* ’c’ : constant only (default) \n",
    "* ’ct’ : constant and trend\n",
    "* ’ctt’ : constant, and linear and quadratic trend\n",
    "* ’nc’ : no constant, no trend"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Correlograms\n",
    "Autocorrelogram & Partial Auto-correlogram is useful that to estimate each models parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use tra.diff()(differenced data), because this time series is unit root process.\n",
    "fig,ax = plt.subplots(2,1,figsize=(20,10))\n",
    "fig = sm.graphics.tsa.plot_acf(y.diff().dropna(), lags=50, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(y.diff().dropna(), lags=50, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "From the ACF and PACF, we will use the lag number  for ARIMA (p = 2,  d= 1, q= ?). Alternatively, we can use : `arma_order_select_ic` method, it is very easy to search best parameters(p,q) of ARMA model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDiff = sm.tsa.arma_order_select_ic(tra, max_ar=7, max_ma=7, ic='aic', trend='c')\n",
    "print('ARMA(p,q) =',resDiff['aic_min_order'],'is the best.')"
   ]
  },
  {
   "source": [
    "## SARIMA model\n",
    "I don't know the best way to estimate `seasonal_order(sp,sd,sq,s)`parameters.\n",
    "parameter s:\n",
    "\n",
    "* 1 for yearly\n",
    "* 4 for quarterly\n",
    "* 12 for monthly\n",
    "* 52 for weekly\n",
    "* 365 for daily"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# For now,we choose period 1.\n",
    "sarima = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(1,1,1,12),\n",
    "                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "sarima.summary()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sarima.resid\n",
    "fig,ax = plt.subplots(2,1,figsize=(15,8))\n",
    "fig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred = sarima.predict(tr_end,te_end)[1:]\n",
    "print('SARIMA model MSE: {}'.format(round(mean_squared_error(tes,pred),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()"
   ]
  },
  {
   "source": [
    "## SARIMAX \n",
    "Added exogenous variable to ARIMA."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Make features1\n",
    "Let's try to make some features.\n",
    "\n",
    "* month\n",
    "* dayofweek\n",
    "* sales_shifted_364(1year_shift)\n",
    "* sales_shifted_728(2year_shift)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales groupby month\n",
    "buf.groupby(buf.index.month).sales.mean().plot();plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales groupby day of week\n",
    "buf.groupby(buf.index.weekday).sales.mean().plot();plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(buf[0:363].sales.dropna().values)\n",
    "plt.plot(buf[364:727].sales.dropna().values);plt.show()"
   ]
  },
  {
   "source": [
    "Feature Creating with Day of week and Month"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = df[(df.item==1)&(df.store==1)].copy()#reset buf\n",
    "buf = buf.set_index('date')\n",
    "buf.index = pd.DatetimeIndex(buf.index).to_period('D')\n",
    "#month one hot encoding\n",
    "buf['month'] = buf.index.month\n",
    "month_dummies = pd.get_dummies(buf['month'])\n",
    "month_dummies.columns = ['month-'+ str(m) for m in range(1,13)]\n",
    "buf = pd.concat([buf, month_dummies], axis=1).drop(['month'],axis=1)\n",
    "#dayofweek one hot encoding\n",
    "buf['dayofweek'] = buf.index.weekday\n",
    "week_dummies = pd.get_dummies(buf['dayofweek'])\n",
    "week_dummies.columns = ['dayofweek-'+ str(w) for w in range(0,7)]\n",
    "buf = pd.concat([buf, week_dummies], axis=1).drop(['dayofweek'],axis=1)\n",
    "#Satday,Sunday\n",
    "buf['weekend'] = (buf.index.dayofweek>4).astype(int)#Saturday,Sunday\n",
    "#Sunday\n",
    "#buf['sunday'] = (buf.index.dayofweek==6).astype(int)#Saturday,Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifted data\n",
    "#buf['sales_shifted_91'] = buf.sales.shift(91)\n",
    "buf['sales_shifted_728'] = buf.sales.shift(728)\n",
    "buf['sales_shifted_364'] = buf.sales.shift(364)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf[['sales_shifted_728','sales_shifted_364']].head(-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf[['sales_shifted_728','sales_shifted_364']].tail()"
   ]
  },
  {
   "source": [
    "### Split Train Test for ARIMAX model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_start,tr_end = '2015-01-01','2017-09-30'\n",
    "te_start,te_end = '2017-10-01','2017-12-31'\n",
    "tra = buf['sales'][tr_start:tr_end].dropna()\n",
    "tes = buf['sales'][te_start:te_end].dropna()\n",
    "exog_train = buf.drop(['store','item','sales'],axis = 1)[tr_start:tr_end].dropna()\n",
    "exog_test = buf.drop(['store','item','sales'],axis = 1)[te_start:te_end].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_train.head()"
   ]
  },
  {
   "source": [
    "## ARIMAX Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(0,0,0,0),exog = exog_train,freq='D',\n",
    "                                  enforce_stationarity=False, enforce_invertibility=False,).fit()\n",
    "arimax.summary()\n",
    "#We can use SARIMAX model as ARIMAX when seasonal_order is (0,0,0,0) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = arimax.resid\n",
    "fig,ax = plt.subplots(2,1,figsize=(15,8))\n",
    "fig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred = arimax.predict(tr_end,te_end,exog = exog_test)[1:]\n",
    "print('ARIMAX model MSE:{}'.format(round(mean_squared_error(tes,pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the ARIMA-x forecasts actual vs predicted. \n",
    "pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of Residuals Analysis of ARIMAX model\n",
    "arimax.plot_diagnostics(figsize=(15, 12))"
   ]
  },
  {
   "source": [
    "## SARIMAX Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(1,1,1,12),exog = exog_train,\n",
    "                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "sarimax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sarimax.resid\n",
    "fig,ax = plt.subplots(2,1,figsize=(15,8))\n",
    "fig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred = sarimax.predict(tr_end,te_end,exog = exog_test)[1:]\n",
    "print('SARIMAX model MSE:{}'.format(mean_squared_error(tes,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax.plot_diagnostics(figsize=(15, 12))"
   ]
  },
  {
   "source": [
    "It seems that ARIMAX model's prediction is better than SARIMAX model's.\n",
    "And because SARIMA(X) model has a issue(seasonal period parameter),we choose ARIMAX model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ARIMAX Model's summary check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The results of Jarque-Bera test and Ljung-Box test provide an indication of the validity of this model.\n",
    "\n",
    "In this model's summary, Jarque-Bera test's Prob is under 0.05.\n",
    "It means that this model's resid is not following a normal distribution.\n",
    "In other words, some infomations still remain in this model's resid.\n",
    "\n",
    "Look at the histgram which was output by plot_diagnostics method, It looks like slightly skew.\n",
    "\n",
    "Ljung-Box test: https://en.wikipedia.org/wiki/Ljung%E2%80%93Box_test\n",
    "\n",
    "Jarque-Bera test: https://en.wikipedia.org/wiki/Jarque%E2%80%93Bera_test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax.resid.plot();plt.show()\n",
    "#It seems that there is outlier in this model's resid on late June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(arimax.resid,columns=['resid'])\n",
    "res_df.sort_values(by='resid',ascending=False).head(5)"
   ]
  },
  {
   "source": [
    "The outlier is the sales in '2017-06-28'.\n",
    "Is the date an anniversary or something?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "piv_val = buf.pivot_table(values='sales',\n",
    "                          index=buf.index.day,\n",
    "                          columns=buf.index.month,\n",
    "                          aggfunc='mean')\n",
    "sns.heatmap(piv_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf[(buf.index.day == 28)&(buf.index.month == 6)]['sales']"
   ]
  },
  {
   "source": [
    "28th June 2017's sales is too big as other 28th June sales!\n",
    "Besides, that one day is a weekday."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data predict\n",
    "pred = arimax.predict(tr_start,tr_end,exog = exog_train)[1:]\n",
    "pd.DataFrame({'train':tra['2017-06-20':'2017-06-30'],\n",
    "              'pred':pred['2017-06-20':'2017-06-30']}).plot();plt.show()"
   ]
  },
  {
   "source": [
    "### Make Features 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier etc...\n",
    "buf['outlier_flag']=0\n",
    "buf.loc[buf.index == '2017-06-28','outlier_flag']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_start,tr_end = '2015-01-01','2017-09-30'\n",
    "te_start,te_end = '2017-10-01','2017-12-31'\n",
    "tra = buf['sales'][tr_start:tr_end].dropna()\n",
    "tes = buf['sales'][te_start:te_end].dropna()\n",
    "exog_train = buf.drop(['store','item','sales'],axis = 1)[tr_start:tr_end].dropna()\n",
    "exog_test = buf.drop(['store','item','sales'],axis = 1)[te_start:te_end].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax_2 = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(0,0,0,0),exog = exog_train,\n",
    "                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\n",
    "arimax_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = arimax_2.resid\n",
    "fig,ax = plt.subplots(2,1,figsize=(15,8))\n",
    "fig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\n",
    "fig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "pred = arimax_2.predict(tr_end,te_end,exog = exog_test)[1:]\n",
    "print('ARIMAX model MSE:{}'.format(mean_squared_error(tes,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimax_2.plot_diagnostics(figsize=(15, 12))"
   ]
  },
  {
   "source": [
    "The histgram looks like still skew, but Jarque-Bera test's Prob is over 0.05.\n",
    "It means that this model's resid is following a normal distribution.\n",
    "\n",
    "An added featrue was useless to grow up predict accuracy.\n",
    "but, we were able to make a better model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Search best parameters\n",
    "We can do grid search on the best parameters for SARIMAX. \n",
    "\n",
    "<font color = 'red'>Be careful as this will take some time to run! </font>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "p = q = range(7,8)\n",
    "pdq = list(itertools.product(p, [1], q))\n",
    "sp = sq = range(1,8)#range(0,1) <- ARIMAX\n",
    "seasonal_pdq = list(itertools.product(sp, [0,1], sq,[12]))#rlist(itertools.product(sp, [0], sq,[0]))<- ARIMAX\n",
    "\n",
    "params = []\n",
    "params_s = []\n",
    "aics = []\n",
    "mses = []\n",
    "cnt = 0\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(tra,\n",
    "                                            order=param,\n",
    "                                            exog = exog_train,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            freq='D',\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            results = mod.fit()\n",
    "\n",
    "            pred = results.get_prediction(start = pd.to_datetime(tr_end),\n",
    "                                      end = pd.to_datetime(te_end),exog=exog_test)\n",
    "\n",
    "            params.append(param)\n",
    "            params_s.append(param_seasonal)\n",
    "            aics.append(results.aic)\n",
    "            mses.append(mean_squared_error(tes,pred.predicted_mean[1:]))\n",
    "\n",
    "\n",
    "            #if cnt % 8 == 0:\n",
    "            print('SARIMAX{}x{} - AIC:{} - MSE:{}'.format(param,\n",
    "                                                            param_seasonal,\n",
    "                                                            results.aic,\n",
    "                                                        mses[-1]))\n",
    "                #cnt += 1\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "min_ind = aics.index(min(aics))\n",
    "bestparam = (params[min_ind],params_s[min_ind])\n",
    "print('best_param_aic:',bestparam,' aic:',min(aics))\n",
    "min_ind = mses.index(min(mses))\n",
    "bestparam = (params[min_ind],params_s[min_ind])\n",
    "print('best_param_mse:',bestparam,' mse:',min(mses))\n",
    "\n",
    "print('Finish!!')"
   ]
  }
 ]
}